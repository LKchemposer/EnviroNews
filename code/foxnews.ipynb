{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fox News\n",
    "\n",
    "Because Fox News does not provide an API or any news archives (at least inaccessible to regular users), Selenium is an excellent tool to scrape its web contents. My objective is only to get URLs of related articles so that I can use the newspaper API to extract and store the full text afterwards. Using Selenium requires installing a chromedriver. The code here consists of:\n",
    "1. Scraping metadata (i.e., headlines, URLs, categories) by looping through various \"categories\" (e.g., environment, carbon emissions, water pollution)\n",
    "2. Visualizing distribution of topical relevance via an arbitrarily determined \"score\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import requests\n",
    "import re\n",
    "import newspaper\n",
    "from newspaper import Article, Source\n",
    "from sqlalchemy import create_engine\n",
    "from IPython import display\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import os\n",
    "chromedriver = '/Applications/chromedriver'\n",
    "os.environ['webdriver.chrome.driver'] = chromedriver\n",
    "\n",
    "import cnfg\n",
    "from pprint import pprint\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "%pylab inline\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a [cateogory page on Fox News](https://www.foxnews.com/category/world/environment) only displays a few headlines with hyperlinks at a time, one must click \"Show More\" to get more (older) articles. However, clicking \"Show More\" refreshes the page (chromedriver's perspective), so I used a variable `prev_n_article` to track the total number of articles after each click to avoid getting metadata from the same articles over and over again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open driver\n",
    "driver = webdriver.Chrome(chromedriver)\n",
    "\n",
    "# paste new category webpages\n",
    "driver.get('http://www.foxnews.com/category/us/environment/carbon-emissions.html')\n",
    "\n",
    "# global params\n",
    "count = 0\n",
    "prev_n_article = 1\n",
    "urls = []\n",
    "\n",
    "while count < 12000:\n",
    "    \n",
    "    # click on SHOW MORE\n",
    "    ipt = driver.find_element_by_xpath('//*[@id=\"wrapper\"]/div/div[2]/div/main/div/footer/div/a')\n",
    "    ipt.send_keys(Keys.RETURN)\n",
    "\n",
    "    # number of articles on screen + 1 (i.e., for 10 articles, loop from article 1 to 10)\n",
    "    n_articles = len(driver.find_elements_by_xpath('//*[@id=\"wrapper\"]/div/div[2]/div/main/div/div/article')) + 1\n",
    "\n",
    "    for i in range(prev_n_article, n_articles):\n",
    "        try:\n",
    "            article_xpath = '//*[@id=\"wrapper\"]/div/div[2]/div/main/div/div/article[{}]/div[2]/header'.format(i)\n",
    "            category_xpath = article_xpath + '/div/span[1]/a'\n",
    "            category = driver.find_element_by_xpath(category_xpath).text\n",
    "            url_xpath = article_xpath + '/h2/a'\n",
    "            url = driver.find_element_by_xpath(url_xpath).get_attribute('href')\n",
    "            hl = driver.find_element_by_xpath(url_xpath).text\n",
    "            urls.append(dict(zip(['headline', 'url', 'category'], [hl, url, category])))\n",
    "            count += 1\n",
    "\n",
    "            # print for debugging\n",
    "            if count % 50 == 0:\n",
    "                display.clear_output()\n",
    "                print(hl, url)\n",
    "\n",
    "            # save to csv, reset dataframe\n",
    "            if count % 100 == 0:\n",
    "                pd.DataFrame(urls).to_csv('foxnews_env.csv', index=False, header=None, mode='a')\n",
    "                urls = []\n",
    "\n",
    "            # reassign number of articles to update loop (filter duplicates)\n",
    "            prev_n_article = n_articles\n",
    "        \n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(urls).to_csv('foxnews_env.csv', index=False, header=None, mode='a')\n",
    "urls = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for Relevance\n",
    "\n",
    "Using keywords from headlines and categories, we can somewhat estimate the relevance of these articles. Here, I broke down headlines and category names into words and counted the word frequencies. I assigned a \"score\" to an article by summing these word frequencies together. My assumption is that, due to these articles being previously categorized, articles whose headlines contain the same words likely talk about the same environment-related topic. In addition, if the headline has a \"critical\" word (e.g., EPA) or if its category is topical (e.g., climate, emissions), I arbitrarily add a bonus 2000 to the relevance score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fox = pd.read_csv('fox_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast tokenization of headlines and category names using count vectorizer\n",
    "head = CountVectorizer()\n",
    "heads = head.fit_transform(fox['headline'])\n",
    "heads_d = dict(pd.DataFrame(heads.toarray(), columns=sorted(head.vocabulary_.keys())).sum())\n",
    "\n",
    "cat = CountVectorizer()\n",
    "cats = cat.fit_transform(fox['category'])\n",
    "cats_d = dict(pd.DataFrame(cats.toarray(), columns=sorted(cat.vocabulary_.keys())).sum())\n",
    "\n",
    "d = Counter(cats_d) + Counter(heads_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relevance(row):\n",
    "    rel = 0\n",
    "    hl = row['headline'].lower().replace('[^a-z ]', '').split()\n",
    "    for i in hl:\n",
    "        if i in d:\n",
    "            rel += d[i]\n",
    "        if i in ['epa']:\n",
    "            rel += 2000\n",
    "    cat = row['category'].lower().split()\n",
    "    for j in cat:\n",
    "        rel += d[j]\n",
    "        if j in ['climate', 'emissions', 'water']:\n",
    "            rel += 2000\n",
    "    return rel\n",
    "\n",
    "fox['relevance'] = fox.apply(relevance, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a204a1978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fox['relevance'].hist(bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be some separation between articles with a \"relevance score\" below and those above 2000, as expected (i.e., articles with a score slightly above 2000 contain the keyword or belongs to a category of interest). However,  due to the limited number of articles scraped from Fox News (\"Show More\" does not necessarily grab all articles in the last decade), I decided not to drop any Fox News articles, and included all of them in the corpus for NLP analysis. Topic modeling results should not be affected drastically, as the low-score articles only account for less than 10% of the entire corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
