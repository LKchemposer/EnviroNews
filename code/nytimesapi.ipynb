{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New York Times API\n",
    "\n",
    "Compared to NewsAPI, the NYTAPI is considerably more frustrating to use. The query keywords are extremely sensitive and the queried articles need excessive checking that they are indeed on topic. I used the [Article Search API](https://developer.nytimes.com/docs/articlesearch-product/1/overview) to get URLs for topical articles before getting the full-text articles via [newspaper API's](https://newspaper.readthedocs.io/en/latest/) full-text functionality. There are open-source Python packages for using NYTAPI, but they do not work properly. As a result, I made GET requests directly to the NYTAPI using the Lucene syntax for query filtering (instead of using an open-source package). One may need to contact NYT at code@nytimes.com to increase their [daily request limit](https://developer.nytimes.com/faq#a11) (4000 requests/day).\n",
    "\n",
    "The code here consists of:\n",
    "1. Querying metadata (e.g., URLs) of articles, storing them in CSVs\n",
    "2. Cleaning article URLs:\n",
    "    1. Using other metadata (e.g., document types, word count)\n",
    "    2. By assessing the relevance of articles via headlines, keywords, and newsdesk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import requests\n",
    "import re\n",
    "from sqlalchemy import create_engine\n",
    "from IPython import display\n",
    "\n",
    "import cnfg\n",
    "from pprint import pprint\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "%pylab inline\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta (with exception handling for null results)\n",
    "def web_url(article):\n",
    "    try:\n",
    "        return article['web_url']\n",
    "    except: return\n",
    "\n",
    "def document_type(article):\n",
    "    try:\n",
    "        return article['document_type']\n",
    "    except: return\n",
    "\n",
    "def type_of_material(article):\n",
    "    try:\n",
    "        return article['type_of_material']\n",
    "    except: return\n",
    "\n",
    "def news_desk(article):\n",
    "    try:\n",
    "        return article['news_desk']\n",
    "    except: return\n",
    "\n",
    "def headline(article):\n",
    "    try:\n",
    "        return article['headline']['main']\n",
    "    except: return\n",
    "\n",
    "def pub_date(article):\n",
    "    try:\n",
    "        return article['pub_date']\n",
    "    except: return\n",
    "\n",
    "\n",
    "def source(article):\n",
    "    try:\n",
    "        return article['source']\n",
    "    except: return\n",
    "\n",
    "\n",
    "def word_count(article):\n",
    "    try:\n",
    "        return article['word_count']\n",
    "    except: return\n",
    "\n",
    "def word_count(article):\n",
    "    try:\n",
    "        return article['word_count']\n",
    "    except: return\n",
    "    \n",
    "def keywords(article):\n",
    "    keys = []\n",
    "    try:\n",
    "        for i in article['keywords']:\n",
    "            keys.append(i['value'])\n",
    "        return keys\n",
    "    except: return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = cnfg.load('/Users/lkchemposer/.nytimes_config')\n",
    "apikey = '&api-key=' + key['api_key'] # registered per instructions at https://developer.nytimes.com/get-started\n",
    "\n",
    "search = 'https://api.nytimes.com/svc/search/v2/articlesearch.json?'\n",
    "\n",
    "# filters\n",
    "body = 'body:(\"environment\" AND (\"pollution\" OR \"air pollution\" OR \"water pollution\" OR \"ocean pollution\" OR \"land pollution\" OR \"noise pollution\" OR \"waste management\" OR \"water quality\" OR \"air quality\" OR \"global warming\" OR (\"global warming\" AND (\"polar bears\" OR \"ice cap melting\")) OR ((\"solar energy\" OR \"solar power\" OR \"solar panels\") AND \"environment\") OR \"climate change\" OR \"climate march\" OR \"recycling\" OR (\"electric cars\" AND \"pollution\") OR \"wind energy\" OR \"deforestation\" OR (\"al gore\" AND \"pollution\") OR (\"planet earth\" OR \"mother earth\" AND \"nature\" AND \"pollution\") OR \"epa\" OR \"greenhouse effect\" OR \"greenhouse gases\" OR (\"fossil fuels\" AND \"pollution\") OR (\"natural resources\" AND \"pollution\") OR (\"sutainability\" AND \"green\") OR \"alternative energy\" OR \"renewable energy\" OR \"earth day\" OR (\"carbon dioxide\" AND \"pollution\") OR \"carbon footprint\" OR \"water conservation\" OR \"energy conservation\" OR \"conservation\" OR \"electronic waste\" OR \"landfill\" OR \"composting\" OR \"department of energy\" OR \"earth science\") OR \"environmental health\" OR \"environmental engineer\" OR \"environmental justice\" OR \"environmental ethics\" OR \"environmental racism\" OR \"environmental sociology\" OR \"environmental geography\" OR (\"environmental education\" OR \"environmental studies\" OR \"environmental science\" AND (\"pollution\" OR \"nature\")))'\n",
    "fq = 'fq=news_desk.contains:(\"Environment\" \"Energy\") OR subject.contains:(\"Environment\" \"Pollution\" \"Climate\" \"Energy\") OR ' + body \n",
    "end = '&end_date=20111119'\n",
    "sort = '&sort=newest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = search + fq + '&page=1' + end + sort + apikey\n",
    "articles = requests.get(queries).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97993"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of total queried articles\n",
    "articles['response']['meta']['hits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Politics and Clean Air\n",
      "Panel Hears Defense of Loan to Solyndra\n",
      "Solyndra Has a Cousin in the Poorhouse\n",
      "Highlighting Influence of Asia Behind Artwork\n",
      "Hip Cities That Think About How They Work\n",
      "The Fracturing of Pennsylvania\n",
      "A Phone App for Switching Out Your Light Bulbs\n",
      "A Phone App for Switching Out Your Light Bulbs\n",
      "Energy Secretary to Defend Solyndra Loan to Congress\n",
      "An Assault on the Amazon\n"
     ]
    }
   ],
   "source": [
    "# check headlines for topic relevance\n",
    "for i in articles['response']['docs']:\n",
    "    print(i['headline']['main'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relevance of Articles\n",
    "\n",
    "Because there is no limit on the number of results and the articles are sorted in order of newest to oldest, the queried articles on page 200 are not likely to be on topic despite being recent. The NYTAPI has a sort option for relevance, but it did not seem to query good topical results. I resolved this issue by:\n",
    "1. Setting a limit to the number of results: 200 maximum pages (10 article/page), and\n",
    "2. Using the last result's previous date as the new \"end date\" for the next queries\n",
    "\n",
    "By limiting the number of results, I ended up with (mostly) topical articles dating back to the 80s. In retrospect, 200 pages seem too many still."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsl = []\n",
    "errs = []\n",
    "end = '&end_date=19801105' # arbitrary, used as anchor point in case of error\n",
    "while True:\n",
    "    for i in range(1, 201): # up to 200 pages, arbitrarily\n",
    "        p = '&page={}'.format(i)\n",
    "        queries = search + fq + p + end + sort + apikey\n",
    "        time.sleep(1)\n",
    "        articles = requests.get(queries).json()\n",
    "        try:\n",
    "            n = articles['response']['docs']\n",
    "            for article in n:\n",
    "                wu = web_url(article)\n",
    "                dt = document_type(article)\n",
    "                tm = type_of_material(article)\n",
    "                nd = news_desk(article)\n",
    "                hl = headline(article)\n",
    "                pdt = pub_date(article)\n",
    "                sc = source(article)\n",
    "                wc = word_count(article)\n",
    "                kw = keywords(article)\n",
    "                news = dict(zip(['web_url', 'document_type', 'type_of_material', 'news_desk',\n",
    "                                 'headline', 'pub_date', 'source', 'word_count', 'keywords'],\n",
    "                                [wu, dt, tm, nd, hl, pdt, sc, wc, kw]))\n",
    "                newsl.append(news)\n",
    "\n",
    "                # store results every 20 pages\n",
    "                if i % 20 == 0:\n",
    "                    display.clear_output() # display progress\n",
    "                    print(i, hl, wu)\n",
    "                    newsdf = pd.DataFrame(newsl)\n",
    "                    newsdf.to_csv('nytimes_env.csv', mode='a', index=False, header=None)\n",
    "                    newsdf = pd.DataFrame()\n",
    "                    newsl = [] # reset variable\n",
    "                    time.sleep(3)\n",
    "                    \n",
    "        except Exception as err:\n",
    "            print(i, err) # log errors\n",
    "            continue\n",
    "\n",
    "    nyt = pd.read_csv('nytimes_env.csv', header=None)\n",
    "    nyt.drop_duplicates(inplace=True)\n",
    "    \n",
    "    # previous date of the last article as the new end date\n",
    "    prevdate = (pd.to_datetime(nyt[4][-1:]) - datetime.timedelta(1)).dt.strftime('%Y%m%d').values[0]\n",
    "    end = '&end_date={}'.format(prevdate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning URLs\n",
    "\n",
    "### Filtering URLs Using Metadata\n",
    "\n",
    "Because I am only interested in full-text articles to explore topics within environmental news, I need to remove some content types which do not have full-text, are not news articles, or do not reach a minimum (arbitrary) word count (50 words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt = pd.read_csv('nytimes_env.csv', names=sorted(['web_url', 'document_type', 'type_of_material', 'news_desk', 'headline', 'pub_date', 'source', 'word_count', 'keywords']))\n",
    "nyt.drop_duplicates('web_url', inplace=True)\n",
    "\n",
    "#drop videos (no text)\n",
    "nyt.drop(nyt[nyt['type_of_material'] == 'Video'].index, inplace=True)\n",
    "\n",
    "#drop paid death notice (not useful)\n",
    "nyt.drop(nyt[nyt['type_of_material'] == 'Paid Death Notice'].index, inplace=True)\n",
    "\n",
    "#drop schedules (not related content)\n",
    "nyt.drop(nyt[nyt['type_of_material'] == 'Schedule'].index, inplace=True)\n",
    "\n",
    "#drop slideshow (not enough text)\n",
    "nyt.drop(nyt[nyt['type_of_material'] == 'Slideshow'].index, inplace=True)\n",
    "\n",
    "#drop op-ed, caption (no text)\n",
    "nyt.drop(nyt[nyt['type_of_material'] == 'Op-Ed; Caption'].index, inplace=True)\n",
    "\n",
    "#drop anything with below 50 words\n",
    "nyt.drop(nyt[nyt['word_count'] < 50].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering by Weight of Keywords\n",
    "\n",
    "Using keywords (tags by NYT), we can use their frequency (among all articles) as a proxy for topical relevance (i.e., if many articles are tagged with the same keywords, they likely talk about the same topic, and presumably, about some environment-related topic). We can also arbitrary assign a \"score\" if we know what we look for: common environment-related words (e.g., climate, energy, pollution). Here, I assign a \"relevance score\" to an article by:\n",
    "1. Adding its keyword frequency\n",
    "2. Adding 20000 (super high score) if its headline contains specific keywords\n",
    "3. Adding 20000 if the newsdesk it is assigned to contains specific keywords\n",
    "\n",
    "We can visualize the distribution of the \"relevance score\" and decide the threshold for pruning our results (explained below). Note that this _ad hoc_ method have nothing to do with the texts in the article, but about pre-assigned keywords by the NYT in addition to my personal preference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn keywords frequency into weights\n",
    "nyt['keywords'] = nyt['keywords'].str.lower().str.strip('[]').str.replace('\\'', '').str.split(', ')\n",
    "\n",
    "keys = nyt['keywords'].apply(pd.Series)\n",
    "key_counts = keys.stack().value_counts()\n",
    "d = dict(key_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_relevance(row):\n",
    "    key = 0\n",
    "    hlkey = 0\n",
    "    ndkey = 0\n",
    "    \n",
    "    for keyword in row['keywords']:\n",
    "        if keyword in d:\n",
    "            key += d[keyword]\n",
    "    \n",
    "    try:\n",
    "        hl = row['headline'].lower().replace('[^a-z ]', '').split()\n",
    "        for word in hl:\n",
    "            if word in d:\n",
    "                hlkey += d[keyword]\n",
    "            if word in ['climate', 'energy', 'pollution']:\n",
    "                key += 20000\n",
    "    except:\n",
    "        hlkey = 0\n",
    "    \n",
    "    try:\n",
    "        nd = row['news_desk'].lower().replace('[^a-z ]', '').split()\n",
    "        for word in nd:\n",
    "            if word in ['science', 'environment', 'climate', 'energy']:\n",
    "                ndkey += 20000\n",
    "    except:\n",
    "        nd = 0\n",
    "    \n",
    "    return key + hlkey + ndkey\n",
    "\n",
    "nyt['relevance'] = nyt.apply(assign_relevance, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2f422f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nyt['relevance'].hist(bins=100);\n",
    "plt.xlim(0, 30000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because I chose a super score of 20000, articles in the range of 0-20000 are ones that did not meet both requirements of the headlines and news desk. Around 5000, there seems to be a good separation point. Also, as I wanted to include the articles in the peak with the score of ~7000, I decided to drop articles below the score of 5000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt.drop(nyt[(nyt['relevance'] < 5000)].index, inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
